---
description: Store AI prompts and results on Irys to create a permanent, verifiable audit trail.
---

import { Callout } from "nextra-theme-docs";

# Storing AI Prompts on Irys

Permanently storing AI prompts and their results is crucial for creating a reliable audit trail. Irys enables this through permanent-onchain storage and [signed receipts containing millisecond-accurate timestamps](/build/d/features/receipts). 

**This guarantees that each stored prompt is verifiable and immutable.**

This is essential for:

1. **Intellectual Property (IP) Protection**:
Having a precise record of the input and output can help resolve disputes over IP rights, proving that the content generated was based on specific inputs used against a specific model.

2. **Model Evolution and Accountability**:
AI models are continuously updated and retrained, meaning their outputs can change over time (even when given the same prompt). By storing prompts along with metadata, you can trace back the specific conditions under which an AI output was generated. 

3. **Compliance and Transparency**:
Regulatory requirements around AI are evolving, and organizations may soon need to demonstrate how and why specific AI-generated content was created. 

<Callout type="info" emoji="ℹ️">
  There is currently no universally accepted standard for representing AI prompts; this guide is based on best practices outlined in OpenAI's documentation.
</Callout>

## Key Elements to Store

To store AI prompts, the following elements should be captured:

- **Prompt Text**: The actual text of the prompt given to the AI model.
- **Timestamp**: The date and time when the prompt was executed.
- **Model Used**: The AI model used (e.g., GPT-4, DALL-E 2).
- **Result**: The output generated by the AI, or a hash of the output.
- **Hashing Algorithm**: If storing a hash of the result, indicate the algorithm used (e.g., SHA-256).

In certain cases, the following will be needed too:

- **Parameters**: Parameters such as `temperature`, `max_tokens`, and `stop_sequences`.
- **Custom Metadata**: Additional metadata that might be relevant, such as purpose, user ID, or application context.

This can be represented as a JSON object:

```json filename="prompt.json"
{
  "prompt_text": "Translate this text from Esperanto to Toki Pona.",
  "created_at": "2024-08-29T15:30:00Z",
  "model": "gpt-4",
  "temperature": 0.7,
  "max_tokens": 150,
  "stop_sequences": ["\n"],
  "metadata": {
    "purpose": "Translation",
    "user_id": "12345"
  },
  "result": {
    "type": "text",
    "output": "kama ante e toki pi jan Esperanto tawa toki pona.",
    "hash": "9a6e38d09ca3e6a8f2f4d1d6234c1a762c3e8a9d",
    "hash_algo": "SHA-256"
  }
}
```

## Storing Results or Hashes

It's not always possible to store the full output generated by the AI prompt. For larger outputs, such as images or videos, storing a hash of the result is more efficient.

<Callout type="info" emoji="ℹ️">
  Hashing provides a lightweight way to verify the output. A hash is a fixed-length string of characters generated from data of any size, used to verify the integrity of that data by ensuring it hasn't been altered.
</Callout>

```json
{
  "prompt_text": "Generate an image of the coolest mascot in the universe.",
  "created_at": "2024-08-29T15:30:00Z",
  "model": "dall-e-2",
  "temperature": 0.8,
  "max_tokens": 0,
  "stop_sequences": [],
  "metadata": {
    "purpose": "Image generation",
    "user_id": "12345"
  },
  "result": {
    "type": "image",
    "url": "https://gateway.irys.xyz/sprite.png",
    "hash": "8c14d8a15f5e7a6d1a9a23387cd5eebc1d2c9e8f",
    "hash_algo": "SHA-256"
  }
}
```

## Uploading the JSON Object to Irys

You can [store](/build/d/storage-cli/commands/upload) the JSON object containing the prompt using the [Irys CLI](/build/d/storage-cli/installation):

```console
irys upload myPrompt.json \
  -n testnet \
  -t ethereum \
  -w 6dd5e....54a120201cb6a \
  --tags Content-Type application/json \
  --provider-url https://sepolia.base.org
```

Or [SDK](/build/d/sdk/api/uploadFile):

```ts
import Irys from "@irys-network/bundler-client";
import * as fs from "fs";
import dotenv from "dotenv";
dotenv.config();
 
const uploadMetadata = async () => {
	const irys = await getIrys();
 
	const fileToUpload = "./myPrompt.json";
	const tags = [{ name: "Content-Type", value: "application/json" }];

	try {
		const response = await irys.uploadFile(fileToUpload, { tags: tags });
		console.log(`File uploaded ==> https://gateway.irys.xyz/${response.id}`);
	} catch (e) {
		console.log("Error uploading file ", e);
	}
};
```

Once your prompt is stored onchain with Irys, you have'll have a permanent record of what was executed and when. 